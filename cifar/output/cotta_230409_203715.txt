[23/04/09 20:37:15] [conf.py:  214]: PyTorch Version: torch=1.11.0+cu102, cuda=10.2, cudnn=7605
[23/04/09 20:37:15] [conf.py:  216]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar100
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: cotta_230409_203715.txt
LOG_TIME: 230409_203715
MODEL:
  ADAPTATION: cotta
  ARCH: Hendrycks2020AugMix_ResNeXt
  EPISODIC: False
OPTIM:
  AP: 0.72
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  MT: 0.999
  NESTEROV: True
  RST: 0.01
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: ./output
TEST:
  BATCH_SIZE: 100
[23/04/09 20:37:18] [cifar100c.py:   36]: test-time adaptation: CoTTA
[23/04/09 20:37:18] [cifar100c.py:  116]: model for adaptation: Hendrycks2020AugMixResNeXtNet(
  (conv_1_3x3): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (stage_1): Sequential(
    (0): ResNeXtBottleneck(
      (conv_reduce): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      )
    )
    (1): ResNeXtBottleneck(
      (conv_reduce): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
    (2): ResNeXtBottleneck(
      (conv_reduce): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
  )
  (stage_2): Sequential(
    (0): ResNeXtBottleneck(
      (conv_reduce): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      )
    )
    (1): ResNeXtBottleneck(
      (conv_reduce): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
    (2): ResNeXtBottleneck(
      (conv_reduce): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
  )
  (stage_3): Sequential(
    (0): ResNeXtBottleneck(
      (conv_reduce): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      )
    )
    (1): ResNeXtBottleneck(
      (conv_reduce): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
    (2): ResNeXtBottleneck(
      (conv_reduce): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_reduce): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)
      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (conv_expand): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn_expand): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): Linear(in_features=1024, out_features=100, bias=True)
)
[23/04/09 20:37:18] [cifar100c.py:  117]: params for adaptation: ['conv_1_3x3.weight', 'bn_1.weight', 'bn_1.bias', 'stage_1.0.conv_reduce.weight', 'stage_1.0.bn_reduce.weight', 'stage_1.0.bn_reduce.bias', 'stage_1.0.conv_conv.weight', 'stage_1.0.bn.weight', 'stage_1.0.bn.bias', 'stage_1.0.conv_expand.weight', 'stage_1.0.bn_expand.weight', 'stage_1.0.bn_expand.bias', 'stage_1.0.downsample.0.weight', 'stage_1.0.downsample.1.weight', 'stage_1.0.downsample.1.bias', 'stage_1.1.conv_reduce.weight', 'stage_1.1.bn_reduce.weight', 'stage_1.1.bn_reduce.bias', 'stage_1.1.conv_conv.weight', 'stage_1.1.bn.weight', 'stage_1.1.bn.bias', 'stage_1.1.conv_expand.weight', 'stage_1.1.bn_expand.weight', 'stage_1.1.bn_expand.bias', 'stage_1.2.conv_reduce.weight', 'stage_1.2.bn_reduce.weight', 'stage_1.2.bn_reduce.bias', 'stage_1.2.conv_conv.weight', 'stage_1.2.bn.weight', 'stage_1.2.bn.bias', 'stage_1.2.conv_expand.weight', 'stage_1.2.bn_expand.weight', 'stage_1.2.bn_expand.bias', 'stage_2.0.conv_reduce.weight', 'stage_2.0.bn_reduce.weight', 'stage_2.0.bn_reduce.bias', 'stage_2.0.conv_conv.weight', 'stage_2.0.bn.weight', 'stage_2.0.bn.bias', 'stage_2.0.conv_expand.weight', 'stage_2.0.bn_expand.weight', 'stage_2.0.bn_expand.bias', 'stage_2.0.downsample.0.weight', 'stage_2.0.downsample.1.weight', 'stage_2.0.downsample.1.bias', 'stage_2.1.conv_reduce.weight', 'stage_2.1.bn_reduce.weight', 'stage_2.1.bn_reduce.bias', 'stage_2.1.conv_conv.weight', 'stage_2.1.bn.weight', 'stage_2.1.bn.bias', 'stage_2.1.conv_expand.weight', 'stage_2.1.bn_expand.weight', 'stage_2.1.bn_expand.bias', 'stage_2.2.conv_reduce.weight', 'stage_2.2.bn_reduce.weight', 'stage_2.2.bn_reduce.bias', 'stage_2.2.conv_conv.weight', 'stage_2.2.bn.weight', 'stage_2.2.bn.bias', 'stage_2.2.conv_expand.weight', 'stage_2.2.bn_expand.weight', 'stage_2.2.bn_expand.bias', 'stage_3.0.conv_reduce.weight', 'stage_3.0.bn_reduce.weight', 'stage_3.0.bn_reduce.bias', 'stage_3.0.conv_conv.weight', 'stage_3.0.bn.weight', 'stage_3.0.bn.bias', 'stage_3.0.conv_expand.weight', 'stage_3.0.bn_expand.weight', 'stage_3.0.bn_expand.bias', 'stage_3.0.downsample.0.weight', 'stage_3.0.downsample.1.weight', 'stage_3.0.downsample.1.bias', 'stage_3.1.conv_reduce.weight', 'stage_3.1.bn_reduce.weight', 'stage_3.1.bn_reduce.bias', 'stage_3.1.conv_conv.weight', 'stage_3.1.bn.weight', 'stage_3.1.bn.bias', 'stage_3.1.conv_expand.weight', 'stage_3.1.bn_expand.weight', 'stage_3.1.bn_expand.bias', 'stage_3.2.conv_reduce.weight', 'stage_3.2.bn_reduce.weight', 'stage_3.2.bn_reduce.bias', 'stage_3.2.conv_conv.weight', 'stage_3.2.bn.weight', 'stage_3.2.bn.bias', 'stage_3.2.conv_expand.weight', 'stage_3.2.bn_expand.weight', 'stage_3.2.bn_expand.bias', 'classifier.weight', 'classifier.bias']
[23/04/09 20:37:18] [cifar100c.py:  118]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    maximize: False
    weight_decay: 0.0
)
[23/04/09 20:37:18] [cifar100c.py:   46]: resetting model
